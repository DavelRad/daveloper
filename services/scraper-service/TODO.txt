SCRAPER-SERVICE gRPC TRANSFORMATION TODO LIST
================================================

PHASE 1: SETUP & DEPENDENCIES
-----------------------------
[x] 1.1 Update requirements.txt
    - Add grpcio==1.59.0
    - Add grpcio-tools==1.59.0
    - Remove flask-jwt-extended==4.5.2
    - Remove flask-bcrypt==1.0.1
    - Remove flask-cors==4.0.0
    - Keep flask==2.3.3 (for now, remove later)
    - Keep other core dependencies

[x] 1.2 Create proto directory and gRPC definitions
    - Create proto/news_scraper.proto
    - Define NewsScraperService
    - Define message types: ScrapeRequest, ScrapeResponse, Article, Summary
    - Define HealthCheck service

[x] 1.3 Generate gRPC Python code
    - Run: python -m grpc_tools.protoc -Iproto --python_out=. --grpc_python_out=. proto/news_scraper.proto
    - Verify generated files: news_scraper_pb2.py, news_scraper_pb2_grpc.py

PHASE 2: REMOVE AUTHENTICATION & USER FEATURES
---------------------------------------------
[x] 2.1 Remove authentication files
    - Delete app/bcrypt.py
    - Delete migrate_users.py

[x] 2.2 Clean up app/__init__.py
    - Remove Flask app factory
    - Remove JWT setup
    - Remove bcrypt setup
    - Remove CORS setup
    - Remove blueprint registration
    - Keep only basic imports and config

[x] 2.3 Simplify app/config.py
    - Remove Flask-specific config
    - Keep MongoDB connection settings
    - Add gRPC server config (port, host)
    - Keep environment variable settings

[x] 2.4 Update app/database.py
    - Remove authentication-related code
    - Keep MongoDB connection setup
    - Simplify to just articles collection
    - Remove user-related database operations

PHASE 3: SIMPLIFY SCHEMAS & DATA MODELS
---------------------------------------
[x] 3.1 Update app/schemas.py
    - Remove user_schema
    - Keep article_schema but simplify
    - Remove user-related fields from article schema
    - Keep: title, content, summary, tags, url, published_date
    - Remove: user_id, likes, user_interactions

[x] 3.2 Update app/services/utils.py
    - Remove user-related utility functions
    - Keep article processing utilities
    - Keep data validation functions
    - Remove authentication helpers

PHASE 4: CREATE gRPC SERVER
---------------------------
[x] 4.1 Create app/grpc_server.py
    - Import generated gRPC classes
    - Create NewsScraperService class
    - Implement ScrapeArticles method
    - Implement GetArticles method
    - Implement HealthCheck method
    - Add proper error handling

[x] 4.2 Create server.py (new entry point)
    - Import grpc server classes
    - Create gRPC server instance
    - Add NewsScraperService to server
    - Configure server port and host
    - Add graceful shutdown handling

PHASE 5: MIGRATE CORE FUNCTIONALITY
----------------------------------
[x] 5.1 Test core services individually
    - Test app/services/scraper.py
    - Test app/services/news_api.py
    - Test app/services/gemini.py
    - Ensure all work without Flask context

[x] 5.2 Integrate services into gRPC methods
    - ScrapeArticles: NewsAPI → Scraper → Gemini → MongoDB
    - GetArticles: Query MongoDB for processed articles
    - HealthCheck: Simple status check

[x] 5.3 Update database operations
    - Remove user-related queries
    - Simplify article CRUD operations
    - Update bulk operations for articles only
    - Remove user likes/interactions

PHASE 6: CLEAN UP ROUTES & REMOVE FLASK
---------------------------------------
[x] 6.1 Remove Flask routes.py
    - Delete entire routes.py file
    - All functionality moved to gRPC server

[x] 6.2 Remove Flask dependencies
    - Remove flask from requirements.txt
    - Remove flask-pymongo (use pymongo directly)
    - Remove marshmallow (use simple dict validation)

[x] 6.3 Update imports throughout codebase
    - Remove Flask imports
    - Update database imports
    - Update service imports

PHASE 7: UPDATE CONFIGURATION FILES
----------------------------------
[x] 7.1 Update Dockerfile
    - Change from Flask to gRPC server
    - Update CMD to run server.py
    - Update EXPOSE port if needed
    - Add proto compilation step

[x] 7.2 Update docker-compose.yml (in root)
    - Add scraper-service to services
    - Configure gRPC port mapping
    - Add environment variables
    - Add health check for gRPC

[x] 7.3 Update README.md
    - Remove Flask instructions
    - Add gRPC server instructions
    - Update environment variables
    - Add proto compilation instructions

PHASE 8: TESTING & VALIDATION
-----------------------------
[x] 8.1 Test gRPC server startup
    - Verify server starts without errors
    - Check port binding
    - Test health check endpoint

[x] 8.2 Test core functionality
    - Test ScrapeArticles method
    - Test GetArticles method
    - Verify MongoDB operations
    - Test error handling

[x] 8.3 Test with gRPC client
    - Create simple test client
    - Test all methods
    - Verify data serialization
    - Test error scenarios

[x] 8.4 Integration testing
    - Test with NestJS gRPC client (when ready)
    - Verify portfolio integration
    - Test end-to-end pipeline

PHASE 9: CLEANUP & OPTIMIZATION
-------------------------------
[x] 9.1 Remove unused files
    - Delete any remaining Flask files
    - Remove unused imports
    - Clean up __pycache__ directories

[x] 9.2 Code optimization
    - Optimize database queries
    - Add proper logging
    - Add error handling
    - Add request/response validation

[x] 9.3 Documentation
    - Update inline comments
    - Add method documentation
    - Update API documentation
    - Add deployment instructions

PHASE 10: DEPLOYMENT READY
--------------------------
[x] 10.1 Environment variables
    - MONGO_URI
    - NEWS_API_KEY
    - GEMINI_API_KEY
    - GRPC_PORT (new)
    - GRPC_HOST (new)

[x] 10.2 Health checks
    - Add proper health check endpoint
    - Add database connectivity check
    - Add external API connectivity check

[x] 10.3 Monitoring
    - Add basic logging
    - Add error tracking
    - Add performance metrics

NOTES:
- Keep core scraping and AI functionality intact
- Focus on demo simplicity, not production features
- Ensure all error handling is robust
- Test each phase before moving to next
- Backup original files before major changes 